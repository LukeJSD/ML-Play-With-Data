{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- If meet id inclues a `/`, it is probably wrong.  Still don't know why, but we won't use Meet_ID anyways.\n",
    "- Kyle has TWO athlete id's, 7109122 and 6459186.  Could be a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf = pd.read_csv('M_athlete_results.csv')\n",
    "fdf = pd.read_csv('F_athlete_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String marks to float times in seconds\n",
    "mdf['Time'] = [utils.Time(m) if (e in utils.event_classification()['Track'] and utils.ismark(m)) else None for e, m in zip(mdf['Event'], mdf['Mark'])]\n",
    "fdf['Time'] = [utils.Time(m) if (e in utils.event_classification()['Track'] and utils.ismark(m)) else None for e, m in zip(fdf['Event'], fdf['Mark'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String events to float distance in meters\n",
    "mdf['Distance'] = [utils.string_to_distance(e) if e in utils.event_classification()['Track'] else None for e in mdf['Event']]\n",
    "fdf['Distance'] = [utils.string_to_distance(e) if e in utils.event_classification()['Track'] else None for e in fdf['Event']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = utils.get_stat_col(mdf, 'Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcnats_m = mdf.loc[mdf['Meet_Name'] == 'NCAA Division II Cross Country Championships'].sort_values(['Place', 'Mark'])\n",
    "xcnats_f = fdf.loc[fdf['Meet_Name'] == 'NCAA Division II Cross Country Championships'].sort_values(['Place', 'Mark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_to_xc(gender, allresults=False, nats=True):\n",
    "    if gender == 'M':\n",
    "        DF = mdf\n",
    "        xcnats = xcnats_m\n",
    "    elif gender == 'F':\n",
    "        DF = fdf\n",
    "        xcnats = xcnats_f\n",
    "    # PRs before a specified year\n",
    "    xcnats_dic = {}\n",
    "    for year in range(2012, 2020):\n",
    "        print(year, end='...')\n",
    "        df1 = DF.loc[((DF['Year'] <= year) & (DF['Season'] != 'Cross Country') & (DF['Distance'] > 0)) | ((DF['Year'] < year) & (DF['Season'] == 'Cross Country'))]\n",
    "        for s in ['Outdoor', 'Indoor']:\n",
    "            records = utils.get_records()[s]\n",
    "            for e, m in records.items():\n",
    "                df1 = df1.loc[(df1['Season'] != s) | (df1['Event'] != e) | ((df1['Season'] == s) & (df1['Event'] == e) & (df1['Time'] >= utils.Time(m)))]\n",
    "        df2 = xcnats.loc[xcnats['Year'] == year]\n",
    "        if allresults:\n",
    "            df3 = df1    # all results rather than just PRs\n",
    "        else:\n",
    "            df3 = df1.sort_values('Time').drop_duplicates(subset=['Athlete ID', 'Distance', 'Season'])    # Season specific PRs?\n",
    "        if nats:\n",
    "            df = df3.join(df2.set_index('Athlete ID'), on='Athlete ID', rsuffix='NATS')\n",
    "        else:\n",
    "            df = df3\n",
    "            df = df[\n",
    "                [\n",
    "                    'Name',\n",
    "                    'Athlete ID',\n",
    "                    'Academic_Year',\n",
    "                    'School', \n",
    "                    'Conference',\n",
    "                    'Meet_Name',\n",
    "                    'Year',\n",
    "                    'Season',\n",
    "                    'Place',\n",
    "                    'Time',\n",
    "                    'Distance',\n",
    "                    'YearNATS',\n",
    "                    'DistanceNATS',\n",
    "                    'PlaceNATS',\n",
    "                    'TimeNATS'\n",
    "                ]\n",
    "            ]\n",
    "            df = df.dropna(subset=['DistanceNATS'])\n",
    "        xcnats_dic[year] = df\n",
    "    print('Done')\n",
    "    return xcnats_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012...2013...2014...2015...2016...2017...2018...2019...Done\n"
     ]
    }
   ],
   "source": [
    "resvar = False\n",
    "natsvar = True\n",
    "xcnats_dic_m = prior_to_xc('M', resvar, natsvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resvar:\n",
    "    assert len(mdf.loc[(mdf['Name']=='KALE ADAMS') & (mdf['Season']=='Cross Country') & (mdf['Year'] < 2019)]) == len(xcnats_dic_m[2019].loc[(xcnats_dic_m[2019]['Name']=='KALE ADAMS') & (xcnats_dic_m[2019]['Season']=='Cross Country')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, df in xcnats_dic_m.items():\n",
    "    champs = df.loc[(df['Meet_Name'].str.contains('Championship')) & (df['Place'] <= 3) & (((df['Year'] < year) & (df['Season'] == 'Cross Country')) | ((df['Year'] <= year) & (df['Season'] != 'Cross Country')))].groupby('Athlete ID').count()\n",
    "    champs['Championship Wins'] = champs['Name']\n",
    "    champs = champs['Championship Wins']\n",
    "    df = df.join(champs, on='Athlete ID')\n",
    "    df['Championship Wins'].fillna(0, inplace=True)\n",
    "    xcnats_dic_m[year] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.DataFrame()\n",
    "for y, d in xcnats_dic_m.items():\n",
    "    DF = pd.concat([DF, d])\n",
    "DF['Time_since_PR'] = DF['YearNATS']-DF['Year']\n",
    "DF, seasondic = utils.make_dummy_col(DF, 'Season')\n",
    "DF = DF.loc[DF['Distance'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf, _ = utils.make_dummy_col(mdf, 'Season', dic=seasondic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdf (66736, 20)\n",
      "2012 (1401, 40)\n",
      "2013 (3075, 40)\n",
      "2014 (4514, 40)\n",
      "2015 (6209, 40)\n",
      "2016 (7832, 40)\n",
      "2017 (9422, 40)\n",
      "2018 (11318, 40)\n",
      "2019 (13410, 40)\n",
      "DF (57181, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Athlete ID</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Academic_Year</th>\n",
       "      <th>School</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Meet_ID</th>\n",
       "      <th>Meet_Name</th>\n",
       "      <th>Meet_Start</th>\n",
       "      <th>Meet_End</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Event</th>\n",
       "      <th>Mark</th>\n",
       "      <th>Place</th>\n",
       "      <th>Prelim/Final</th>\n",
       "      <th>Time</th>\n",
       "      <th>Distance</th>\n",
       "      <th>TimeAVG</th>\n",
       "      <th>TimeSTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8478</th>\n",
       "      <td>DYLAN KO</td>\n",
       "      <td>6612154</td>\n",
       "      <td>JR</td>\n",
       "      <td>3</td>\n",
       "      <td>COLORADO MINES</td>\n",
       "      <td>Rocky Mountain AC</td>\n",
       "      <td>14913</td>\n",
       "      <td>NCAA Division II Outdoor Track &amp; Field Champio...</td>\n",
       "      <td>May 23, 2019</td>\n",
       "      <td>May 25, 2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>31:38.52</td>\n",
       "      <td>9.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1898.52</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1865.26</td>\n",
       "      <td>29.519524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8479</th>\n",
       "      <td>DYLAN KO</td>\n",
       "      <td>6612154</td>\n",
       "      <td>JR</td>\n",
       "      <td>3</td>\n",
       "      <td>COLORADO MINES</td>\n",
       "      <td>Rocky Mountain AC</td>\n",
       "      <td>16015</td>\n",
       "      <td>RMAC Outdoor Track &amp; Field Championships</td>\n",
       "      <td>Apr 26, 2019</td>\n",
       "      <td>Apr 28, 2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>30:42.17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1842.17</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1865.26</td>\n",
       "      <td>29.519524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>DYLAN KO</td>\n",
       "      <td>6612154</td>\n",
       "      <td>JR</td>\n",
       "      <td>3</td>\n",
       "      <td>COLORADO MINES</td>\n",
       "      <td>Rocky Mountain AC</td>\n",
       "      <td>16713</td>\n",
       "      <td>Mines Kit Mayer Invite</td>\n",
       "      <td>Apr 13, 2019</td>\n",
       "      <td>Apr 13, 2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>30:55.09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1855.09</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1865.26</td>\n",
       "      <td>29.519524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8481</th>\n",
       "      <td>DYLAN KO</td>\n",
       "      <td>6612154</td>\n",
       "      <td>JR</td>\n",
       "      <td>3</td>\n",
       "      <td>COLORADO MINES</td>\n",
       "      <td>Rocky Mountain AC</td>\n",
       "      <td>58041</td>\n",
       "      <td>CU Invitational 2018</td>\n",
       "      <td>Apr 6, 2018</td>\n",
       "      <td>Apr 7, 2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>4:04.92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>F</td>\n",
       "      <td>244.92</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>244.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name  Athlete ID Grade Academic_Year          School  \\\n",
       "8478  DYLAN KO     6612154    JR             3  COLORADO MINES   \n",
       "8479  DYLAN KO     6612154    JR             3  COLORADO MINES   \n",
       "8480  DYLAN KO     6612154    JR             3  COLORADO MINES   \n",
       "8481  DYLAN KO     6612154    JR             3  COLORADO MINES   \n",
       "\n",
       "             Conference Meet_ID  \\\n",
       "8478  Rocky Mountain AC   14913   \n",
       "8479  Rocky Mountain AC   16015   \n",
       "8480  Rocky Mountain AC   16713   \n",
       "8481  Rocky Mountain AC   58041   \n",
       "\n",
       "                                              Meet_Name    Meet_Start  \\\n",
       "8478  NCAA Division II Outdoor Track & Field Champio...  May 23, 2019   \n",
       "8479           RMAC Outdoor Track & Field Championships  Apr 26, 2019   \n",
       "8480                             Mines Kit Mayer Invite  Apr 13, 2019   \n",
       "8481                               CU Invitational 2018   Apr 6, 2018   \n",
       "\n",
       "          Meet_End  Year Season  Event      Mark  Place Prelim/Final     Time  \\\n",
       "8478  May 25, 2019  2019      0  10000  31:38.52    9.0            F  1898.52   \n",
       "8479  Apr 28, 2019  2019      0  10000  30:42.17    4.0            F  1842.17   \n",
       "8480  Apr 13, 2019  2019      0  10000  30:55.09    4.0            F  1855.09   \n",
       "8481   Apr 7, 2018  2018      0   1500   4:04.92   32.0            F   244.92   \n",
       "\n",
       "      Distance  TimeAVG    TimeSTD  \n",
       "8478   10000.0  1865.26  29.519524  \n",
       "8479   10000.0  1865.26  29.519524  \n",
       "8480   10000.0  1865.26  29.519524  \n",
       "8481    1500.0   244.92        NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('mdf', mdf.shape)\n",
    "for k, v in xcnats_dic_m.items():\n",
    "    print(k, v.shape)\n",
    "print('DF', DF.shape)\n",
    "seasondic\n",
    "mdf.loc[(mdf['Season'] == 0) & (mdf['Name']=='DYLAN KO')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xcnats_m\n",
    "del xcnats_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_training_scores(ks, model_features, model_labels):\n",
    "    \"\"\"Determine the f1-score of k values for kNN on a given data set\n",
    "    Args:\n",
    "        ks (int iterable): iterable of all the k values to apply\n",
    "        model_features (iterable): the features from the model set to train on\n",
    "        model_labels (iterable): the labels from the model set to train on\n",
    "        \n",
    "    Returns:\n",
    "        dictionary: key is the k value and value is the weighted f1_score on the training set\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    dictionary = {}\n",
    "    for k in ks:\n",
    "      knn = KNeighborsClassifier(n_neighbors=k)\n",
    "      knn.fit(model_features, model_labels)\n",
    "      validationPredictions = knn.predict(model_features)\n",
    "      f1 = f1_score(model_labels, validationPredictions, average=\"weighted\")\n",
    "      dictionary[k] = f1\n",
    "    return dictionary\n",
    "\n",
    "def get_knn_validation_scores(ks, model_features, model_labels, validation_features, validation_labels):\n",
    "    \"\"\"Train a model on a dataset then return the F-1 score on another set\n",
    "    Args:\n",
    "        ks (int iterable): iterable of all the k values to apply\n",
    "        model_features (iterable): the features from the model set to train on\n",
    "        model_labels (iterable): the labels from the model set to train on\n",
    "        validation_features (iterable): the features from the validation set to test on\n",
    "        validation_labels (iterable): the labels from the validation set to test on\n",
    "        \n",
    "    Returns:\n",
    "        dictionary: key is the k value and value is the weighted f1_score on the validation set\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    dictionary = {}\n",
    "    for k in ks:\n",
    "      knn = KNeighborsClassifier(n_neighbors=k)\n",
    "      knn.fit(model_features, model_labels)\n",
    "      validationPredictions = knn.predict(validation_features)\n",
    "      f1 = f1_score(validation_labels, validationPredictions, average=\"weighted\")\n",
    "      dictionary[k] = f1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "allamerican = True\n",
    "target = 'PlaceNATS'\n",
    "features = ['Distance', 'Season', 'Time', 'Time_since_PR', 'Championship Wins', 'TimeAVG', 'TimeSTD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = utils.get_train_test(DF, target, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if allamerican:\n",
    "    y_train[y_train<=40] = 1\n",
    "    y_train[y_train>40] = 0\n",
    "    y_test[y_test<=40] = 1\n",
    "    y_test[y_test>40] = 0\n",
    "else:\n",
    "    categories = 2\n",
    "    width = 100\n",
    "    for i in range(1, categories+1):\n",
    "        y_train[(y_train<=i*width) & (y_train>(i-1)*width)] = float(i)\n",
    "    y_train[y_train>categories*width] = float(categories+1)\n",
    "    for i in range(1, categories+1):\n",
    "        y_test[(y_test<=i*width) & (y_test>(i-1)*width)] = float(i)\n",
    "    y_test[y_test>categories*width] = float(categories+1)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model, X_valid, y_model, y_valid = train_test_split(X_train, y_train, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksToTest = [1,3,5,7,10,20,50,100]\n",
    "training_scores = get_knn_training_scores(ksToTest, X_model, y_model)\n",
    "validation_scores = get_knn_validation_scores(ksToTest, X_model, y_model, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(training_scores, name=\"Training\").plot(kind=\"line\")\n",
    "pd.Series(validation_scores, name=\"Validation\").plot(kind=\"line\", label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksToTest = list(range(1, 26, 2))\n",
    "training_scores = get_knn_training_scores(ksToTest, X_model, y_model)\n",
    "validation_scores = get_knn_validation_scores(ksToTest, X_model, y_model, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-75ddbaee1b37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Validation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"line\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Validation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"k\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1-score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_scores' is not defined"
     ]
    }
   ],
   "source": [
    "pd.Series(training_scores, name=\"Training\").plot(kind=\"line\")\n",
    "pd.Series(validation_scores, name=\"Validation\").plot(kind=\"line\", label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "bestk = 7\n",
    "plt.plot([bestk, bestk], [0.77, 0.9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(bestk)\n",
    "clf.fit(X_train, y_train)\n",
    "testPredictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "\n",
      "[[2007  103]\n",
      " [ 283  151]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.95      0.91      2110\n",
      "         1.0       0.59      0.35      0.44       434\n",
      "\n",
      "    accuracy                           0.85      2544\n",
      "   macro avg       0.74      0.65      0.68      2544\n",
      "weighted avg       0.83      0.85      0.83      2544\n",
      "\n",
      "\n",
      "\n",
      "F1-Score:\n",
      "\n",
      "0.8315256558565027\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix: \\n\")\n",
    "print(confusion_matrix(y_test, testPredictions))\n",
    "print(\"\\n\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, testPredictions))\n",
    "print('\\n\\nF1-Score:\\n')\n",
    "print(f1_score(y_test, testPredictions, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests2020 = [\n",
    "    ('LUKE JULIAN', 5.),\n",
    "    ('DYLAN KO', 2.),\n",
    "    ('KYLE MORAN', 1.),\n",
    "    ('LUC HAGEN', 1.),\n",
    "    ('JAKE MITCHEM', 3.),\n",
    "    ('MAX SEVCIK', .0),\n",
    "    ('CHRIS CATHCART', .0),\n",
    "    ('BO RAADAM', .0),\n",
    "    ('TAYLOR STACK', 9.),\n",
    "    ('CHARLIE SWEENEY', 4.),\n",
    "    ('CARSON BIX', 1.),\n",
    "    ('ISAIAH RODARTE', 1.)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUKE JULIAN 0.6521739130434783\n",
      "DYLAN KO 0.6956521739130435\n",
      "KYLE MORAN 0.625\n",
      "LUC HAGEN 0.4857142857142857\n",
      "JAKE MITCHEM 0.25\n",
      "MAX SEVCIK 0.3529411764705882\n",
      "CHRIS CATHCART 0.125\n",
      "BO RAADAM 0.5\n",
      "TAYLOR STACK 0.6101694915254237\n",
      "CHARLIE SWEENEY 0.6571428571428571\n",
      "CARSON BIX 0.8571428571428571\n",
      "ISAIAH RODARTE 0.7096774193548387\n"
     ]
    }
   ],
   "source": [
    "inv_map = {v: k for k, v in seasondic.items()}\n",
    "year = 2020\n",
    "xc = inv_map['Cross Country']\n",
    "for i in tests2020:\n",
    "    name = i[0]\n",
    "    c = i[1]\n",
    "    if name != 'KYLE MORAN':\n",
    "        subject = mdf.loc[(mdf['Name']==name) & (mdf['Distance'] > 0) & (((mdf['Year'] <= year) & (mdf['Season'].values != xc) & (mdf['Distance'] > 0)) | ((mdf['Year'] < year) & (mdf['Season'].values == xc)))]\n",
    "    else:\n",
    "        subject = mdf.loc[(mdf['Athlete ID']==7109122) & (mdf['Name']==name) & (mdf['Distance'] > 0) & (((mdf['Year'] <= year) & (mdf['Season'].values != xc) & (mdf['Distance'] > 0)) | ((mdf['Year'] < year) & (mdf['Season'].values == xc)))]\n",
    "    subject['Time_since_PR'] = 2020-subject['Year']\n",
    "    subject['Championship Wins'] = [c] * len(subject)\n",
    "    data = subject.sort_values('Time').drop_duplicates('Event')\n",
    "    data = data[features].fillna(.0)\n",
    "\n",
    "    pred = clf.predict(data.to_numpy())\n",
    "\n",
    "    data['Prediction'] = [p for p in pred]\n",
    "    data['All-American?'] = ['Yes' if p==1. else 'No' for p in pred]\n",
    "\n",
    "    counts = subject['Distance'].astype(str) + ' ' + subject['Season'].astype(str)    # distinguish seasons\n",
    "    counts = (counts.value_counts() / len(subject)).to_dict()\n",
    "\n",
    "    data = data[['Distance', 'Season', 'Prediction']].to_numpy()\n",
    "    \n",
    "    weights = []\n",
    "    #for k, v in mycounts.items():\n",
    "    for row in data:\n",
    "        # print(row, '\"'+str(row[0])+' '+str(int(row[1]))+'\"', counts[str(row[0])+' '+str(int(row[1]))])\n",
    "        weights.append(row[2]*counts[str(row[0])+' '+str(int(row[1]))])    # *(row[0]/5000)**0.5\n",
    "    print(name, sum(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mines\n",
    "- LUKE JULIAN 0.6521739130434783\n",
    "- DYLAN KO 0.6956521739130435\n",
    "- KYLE MORAN 0.625\n",
    "- LUC HAGEN 0.4857142857142857\n",
    "- JAKE MITCHEM 0.25\n",
    "- MAX SEVCIK 0.3529411764705882\n",
    "- CHRIS CATHCART 0.125\n",
    "- BO RAADAM 0.5\n",
    "## Western\n",
    "- TAYLOR STACK 0.6101694915254237\n",
    "- CHARLIE SWEENEY 0.6571428571428571\n",
    "## Adams\n",
    "- CARSON BIX 0.8571428571428571\n",
    "- ISAIAH RODARTE 0.7096774193548387\n",
    "\n",
    "<br><br>\n",
    "This may be skewed toward the longer distances and event specialists.  Kyle and Dylan probably would be higher if covid hadn't ended track before they could improve their resumes further.  I don't know how Stack is so low, it might be because he's run a lot of 3ks but all at altitude.  Looks like you need to run well in your most common event.  If Stack ran 5000s as much as he runs 3000s (inflated by steeple), he'd score high.\n",
    "\n",
    "*MAKE SURE ALL DUMMIES ARE THE SAME. THIS MAY BE CAUSING PROBLEMS WHEN get_dummies IS CALLED MORE THAN ONCE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
